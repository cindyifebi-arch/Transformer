# NLP Dissertation Project – Transformer & LSTM Models

This repository contains Jupyter Notebooks developed as part of my MSc dissertation project on Natural Language Processing (NLP).

## 📁 Notebooks
- `P-004371 Transformer.ipynb`: Code for loading data, building, training, and evaluating a Transformer-based NLP model.
- `P-004371 LSTM.ipynb`: Implementation of an LSTM model for sequence modeling tasks and comparison with Transformer performance.

## 🎯 Project Objective
To compare the performance of LSTM and Transformer architectures on a text classification task and analyze their effectiveness in different scenarios using evaluation metrics like accuracy, F1-score, and confusion matrix.

## 🛠️ Tools & Libraries
- Python 3.10+
- PyTorch
- HuggingFace Transformers
- Scikit-learn
- Pandas, NumPy, Matplotlib
- Datasets, Evaluate, Imbalanced-learn
- BeautifulSoup (for text cleaning)

## 📦 Requirements
See the `requirements.txt` file.

## 📊 Output
All results, graphs, and evaluation reports are included in the notebook cells.

## 🔒 Repository
This repo is intended for academic purposes only.
