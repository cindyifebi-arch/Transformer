# NLP Dissertation Project â€“ Transformer & LSTM Models

This repository contains Jupyter Notebooks developed as part of my MSc dissertation project on Natural Language Processing (NLP).

## ğŸ“ Notebooks
- `P-004371 Transformer.ipynb`: Code for loading data, building, training, and evaluating a Transformer-based NLP model.
- `P-004371 LSTM.ipynb`: Implementation of an LSTM model for sequence modeling tasks and comparison with Transformer performance.

## ğŸ¯ Project Objective
To compare the performance of LSTM and Transformer architectures on a text classification task and analyze their effectiveness in different scenarios using evaluation metrics like accuracy, F1-score, and confusion matrix.

## ğŸ› ï¸ Tools & Libraries
- Python 3.10+
- PyTorch
- HuggingFace Transformers
- Scikit-learn
- Pandas, NumPy, Matplotlib
- Datasets, Evaluate, Imbalanced-learn
- BeautifulSoup (for text cleaning)

## ğŸ“¦ Requirements
See the `requirements.txt` file.

## ğŸ“Š Output
All results, graphs, and evaluation reports are included in the notebook cells.

## ğŸ”’ Repository
This repo is intended for academic purposes only.
